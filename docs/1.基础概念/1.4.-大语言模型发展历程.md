# 1.4. 大语言模型发展历程
<link rel="stylesheet" type="text/css" href="15fe2a1330035438.css">
## 															大语言模型发展历程





### StableLM

- 发布时间2023-04-20
- 模型参数30 亿 & 70 亿
- 公司/机构Stability AI
- 论文[Stability AI Launches the First of its StableLM Suite of Language Models](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)



### Koala<img src="http://static.runoob.com/images/runoob-logo.png" class="rounded-full bg-neutral-50 p-0.5">

- 发布时间2023-04-03
- 模型参数130 亿
- 公司/机构Berkeley Artificial Intelligence Research
- 论文[Koala: A Dialogue Model for Academic Research](https://bair.berkeley.edu/blog/2023/04/03/koala/)



### icuna-13B

- 发布时间2023-03-31
- 模型参数130 亿
- 公司/机构LM-SYS
- 论文[Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality](https://vicuna.lmsys.org/)

BloombergGPT

- 发布时间2023-03-30
- 模型参数500 亿
- 公司/机构Bloomberg
- 论文[BloombergGPT: A Large Language Model for Finance](https://briefgpt.xyz/a/2303.17564)

![img](https://briefgpt.xyz/company/nomic.png)

GPT4All

- 发布时间2023-03-29
- 模型参数70 亿
- 公司/机构Nomic AI
- 论文[GPT4All: Training an Assistant-style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo](https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf)

![img](https://briefgpt.xyz/company/databricks.png)

Dolly

- 发布时间2023-03-24
- 模型参数60 亿
- 公司/机构Databricks
- 论文[Hello Dolly: Democratizing the magic of ChatGPT with open models](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html)

![img](https://briefgpt.xyz/company/tsinghua.png)

ChatGLM-6B

- 发布时间2023-03-14
- 模型参数62 亿
- 公司/机构清华大学
- 论文[ChatGLM-6B: An Open Bilingual Dialogue Language Model](https://github.com/THUDM/ChatGLM-6B)

![img](https://briefgpt.xyz/company/openai.svg)

GPT-4

- 发布时间2023-03-14
- 模型参数未知
- 公司/机构OpenAI
- 论文[GPT-4 Technical Report](https://openai.com/research/gpt-4)

![img](https://briefgpt.xyz/company/stanford.png)

Stanford Alpaca

- 发布时间2023-03-13
- 模型参数70 亿
- 公司/机构Stanford
- 论文[Alpaca: A Strong, Replicable Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html)

![img](https://briefgpt.xyz/company/meta.png)

LLaMA

- 发布时间2023-02-24
- 模型参数70 亿 ～ 650 亿
- 公司/机构Meta
- 论文[LLaMA: Open and Efficient Foundation Language Models](https://briefgpt.xyz/a/2302.13971)

![img](https://briefgpt.xyz/company/openai.svg)

GPT-3.5

- 发布时间2022-11-30
- 模型参数1750 亿
- 公司/机构OpenAI
- 论文[GPT-3.5 Model](https://platform.openai.com/docs/models/gpt-3-5)

![img](https://briefgpt.xyz/company/bigscience.png)

BLOOM

- 发布时间2022-11-09
- 模型参数1760 亿
- 公司/机构BigScience
- 论文[BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://briefgpt.xyz/a/2211.05100)

![img](https://briefgpt.xyz/company/bigscience.png)

BLOOMZ

- 发布时间2022-11-03
- 模型参数1760 亿
- 公司/机构BigScience
- 论文[Crosslingual Generalization through Multitask Finetuning](https://briefgpt.xyz/a/2211.01786)

![img](https://briefgpt.xyz/company/bigscience.png)

mT0

- 发布时间2022-11-03
- 模型参数130 亿
- 公司/机构BigScience
- 论文[Crosslingual Generalization through Multitask Finetuning](https://briefgpt.xyz/a/2211.01786)

![img](https://briefgpt.xyz/company/google.png)

Flan-U-PaLM

- 发布时间2022-10-20
- 模型参数5400 亿
- 公司/机构Google
- 论文[Scaling Instruction-Finetuned Language Models](https://briefgpt.xyz/a/2210.11416)

![img](https://briefgpt.xyz/company/google.png)

Flan-T5

- 发布时间2022-10-20
- 模型参数110 亿
- 公司/机构Google
- 论文[Scaling Instruction-Finetuned Language Models](https://briefgpt.xyz/a/2210.11416)

![img](https://briefgpt.xyz/company/wechat.png)

WeLM

- 发布时间2022-09-21
- 模型参数100 亿
- 公司/机构微信
- 论文[WeLM: A Well-Read Pre-trained Language Model for Chinese](https://briefgpt.xyz/a/2209.10372)

![img](https://briefgpt.xyz/company/damo.png)

PLUG

- 发布时间2022-09-01
- 模型参数270 亿
- 公司/机构阿里达摩院
- 论文[PLUG: Pre-training for Language Understanding and Generation](https://github.com/alibaba/AliceMind/tree/main/PLUG)

![img](https://briefgpt.xyz/company/meta.png)

OPT

- 发布时间2022-05-02
- 模型参数1750 亿
- 公司/机构Meta
- 论文[OPT: Open Pre-trained Transformer Language Models](https://briefgpt.xyz/a/2205.01068)

![img](https://briefgpt.xyz/company/google.png)

PaLM

- 发布时间2022-04-05
- 模型参数5400 亿
- 公司/机构Google
- 论文[PaLM: Scaling Language Modeling with Pathways](https://briefgpt.xyz/a/2204.02311)

![img](https://briefgpt.xyz/company/google.png)

Chinchilla

- 发布时间2022-03-29
- 模型参数700 亿
- 公司/机构Google DeepMind
- 论文[Training Compute-Optimal Large Language Models](https://briefgpt.xyz/a/2203.15556)

![img](https://briefgpt.xyz/company/salesforce.png)

CodeGen

- 发布时间2022-03-25
- 模型参数160 亿
- 公司/机构Salesforce
- 论文[CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis](https://briefgpt.xyz/a/2203.13474)

![img](https://briefgpt.xyz/company/tsinghua.png)

GLM-130B

- 发布时间2022-03-17
- 模型参数1300 亿
- 公司/机构清华大学
- 论文[GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://briefgpt.xyz/a/2103.10360)

![img](https://briefgpt.xyz/company/openai.svg)

Instruct GPT

- 发布时间2022-03-04
- 模型参数1750 亿
- 公司/机构OpenAI
- 论文[Training Language Models to Follow Instructions with Human Feedback](https://briefgpt.xyz/a/2203.02155)

![img](https://briefgpt.xyz/company/google.png)

AlphaCode

- 发布时间2022-02-08
- 模型参数410 亿
- 公司/机构Google DeepMind
- 论文[Competition-Level Code Generation with AlphaCode](https://briefgpt.xyz/a/2203.07814)

![img](https://briefgpt.xyz/company/microsoft.png)

MT-NLG

- 发布时间2022-01-28
- 模型参数5300 亿
- 公司/机构Microsoft
- 论文[Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model](https://briefgpt.xyz/a/2201.11990)

![img](https://briefgpt.xyz/company/google.png)

LaMDA

- 发布时间2022-01-20
- 模型参数1370 亿
- 公司/机构Google
- 论文[LaMDA: Language Models for Dialog Applications ](https://briefgpt.xyz/a/2201.08239)

![img](https://briefgpt.xyz/company/openai.svg)

WebGPT

- 发布时间2021-12-17
- 模型参数1750 亿
- 公司/机构OpenAI
- 论文[WebGPT: Browser-assisted question-answering with human feedback](https://briefgpt.xyz/a/2112.09332)

![img](https://briefgpt.xyz/company/google.png)

GLaM

- 发布时间2021-12-13
- 模型参数12000 亿
- 公司/机构Google
- 论文[GLaM: Efficient Scaling of Language Models with Mixture-of-Experts](https://briefgpt.xyz/a/2112.06905)

![img](https://briefgpt.xyz/company/google.png)

Gopher

- 发布时间2021-12-08
- 模型参数2800 亿
- 公司/机构Google DeepMind
- 论文[Scaling Language Models: Methods, Analysis & Insights from Training Gopher](https://briefgpt.xyz/a/2112.11446)

![img](https://briefgpt.xyz/company/huggingface.svg)

T0

- 发布时间2021-10-15
- 模型参数110 亿
- 公司/机构Hugging Face
- 论文[Multitask Prompted Training Enables Zero-Shot Task Generalization](https://briefgpt.xyz/a/2110.08207)

![img](https://briefgpt.xyz/company/google.png)

FLAN

- 发布时间2021-09-03
- 模型参数1370 亿
- 公司/机构Google
- 论文[Finetuned Language Models Are Zero-Shot Learners](https://briefgpt.xyz/a/2109.01652)

![img](https://briefgpt.xyz/company/openai.svg)

Codex

- 发布时间2021-07-07
- 模型参数120 亿
- 公司/机构OpenAI
- 论文[Evaluating large language models trained on code](https://briefgpt.xyz/a/2107.03374)

![img](https://briefgpt.xyz/company/baidu.svg)

ERNIE 3.0

- 发布时间2021-07-05
- 模型参数100 亿
- 公司/机构百度
- 论文[ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation](https://briefgpt.xyz/a/2107.02137)

![img](https://briefgpt.xyz/company/huawei.png)

PanGu-Alpha

- 发布时间2021-04-26
- 模型参数2000 亿
- 公司/机构华为
- 论文[PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation](https://briefgpt.xyz/a/2104.12369)

![img](https://briefgpt.xyz/company/openai.svg)

Switch Transformer

- 发布时间2021-01-11
- 模型参数16000 亿
- 公司/机构Google
- 论文[Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://briefgpt.xyz/a/2101.03961)

![img](https://briefgpt.xyz/company/google.png)

mT5

- 发布时间2020-10-22
- 模型参数130 亿
- 公司/机构Google
- 论文[mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer](https://briefgpt.xyz/a/2010.11934)

![img](https://briefgpt.xyz/company/google.png)

GShard

- 发布时间2020-06-30
- 模型参数6000 亿
- 公司/机构Google
- 论文[GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://briefgpt.xyz/a/2006.16668)

![img](https://briefgpt.xyz/company/openai.svg)

GPT-3

- 发布时间2020-05-28
- 模型参数1750 亿
- 公司/机构OpenAI
- 论文[Language Models are Few-Shot Learners](https://briefgpt.xyz/a/2005.14165)

![img](https://briefgpt.xyz/company/microsoft.png)

Turing-NLG

- 发布时间2020-02-13
- 模型参数170 亿
- 公司/机构Microsoft
- 论文[Turing-NLG: A 17-billion-parameter language model by Microsoft](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/)

![img](https://briefgpt.xyz/company/google.png)

T5

- 发布时间2019-10-23
- 模型参数110 亿
- 公司/机构Google
- 论文[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://briefgpt.xyz/a/1910.10683)

![img](https://briefgpt.xyz/company/google.png)

XLNet

- 发布时间2019-06-19
- 模型参数3.4 亿
- 公司/机构Google Brain
- 论文[XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://briefgpt.xyz/a/1906.08237)

![img](https://briefgpt.xyz/company/baidu.svg)

Baidu-ERNIE

- 发布时间2019-04-19
- 模型参数3.4 亿
- 公司/机构百度
- 论文[ERNIE: Enhanced Representation through Knowledge Integration](https://briefgpt.xyz/a/1904.09223)

![img](https://briefgpt.xyz/company/openai.svg)

GPT-2

- 发布时间2019-02-14
- 模型参数15 亿
- 公司/机构OpenAI
- 论文[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)

!(https://briefgpt.xyz/company/google.png)

BERT

- 发布时间2018-10-11
- 模型参数3.4 亿
- 公司/机构Google
- 论文[Bidirectional Encoder Representations from Transformers](https://briefgpt.xyz/a/1810.04805)



GPT-1

- 发布时间2018-06-11
- 模型参数1.17 亿
- 公司/机构OpenAI
- 论文[Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
